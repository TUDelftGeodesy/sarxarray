{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25d56aa-5366-41f4-8fff-e7a52926c83a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://raw.githubusercontent.com/mbakker7/exploratory_computing_with_python/master/tudelft_logo.png\" WIDTH=200 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "### ALOS-2 - InSAR datamodel based on sarxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ed1b4f-30a0-4b1e-90c6-8dee1f76ea99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sarxarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from scipy.ndimage import uniform_filter\n",
    "from scipy.spatial import KDTree\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from matplotlib.dates import DateFormatter, DayLocator\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from skimage.util import view_as_windows\n",
    "\n",
    "from scipy.linalg import svd\n",
    "from scipy.linalg import inv\n",
    "from scipy.linalg import pinv\n",
    "from scipy.ndimage import generic_filter, label\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "import re\n",
    "import os\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd603ee6-6cb1-462e-acfd-6cb02cbd7fcf",
   "metadata": {},
   "source": [
    "### Specify path of file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac51b80-8173-4fb6-87c4-8db1f66b7154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = Path('data_alos2_seus_p36/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a43521-cb3a-48ca-b100-7ee2e2296a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20140917/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20150204/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20150916/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20160914/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20170201/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20180117/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20180328/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20181024/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20190102/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20190327/cint_srd.raw'),\n",
       " PosixPath('data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/20200101/cint_srd.raw')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ifgs = [p for p in path.rglob('*cint_srd.raw') if not str(p).endswith('20180117\\cint_srd.raw')]\n",
    "list_ifgs.sort()\n",
    "list_ifgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03335612-69bd-4292-99d1-56d14ad1cd47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(list_ifgs)):\n\u001b[1;32m      5\u001b[0m     prep_date_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(list_ifgs[i])\n\u001b[0;32m----> 6\u001b[0m     date \u001b[38;5;241m=\u001b[39m \u001b[43mprep_date_string\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m     date_list\u001b[38;5;241m.\u001b[39mappend(date)\n\u001b[1;32m      9\u001b[0m date_to_add \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20180117\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# USERCHANGE 2\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#  Create date list to keep track of each radar image\n",
    "\n",
    "date_list = []\n",
    "for i in range(len(list_ifgs)):\n",
    "    prep_date_string = str(list_ifgs[i])\n",
    "    date = prep_date_string.split('\\\\')[2]\n",
    "    date_list.append(date)\n",
    "\n",
    "date_to_add = '20180117'  # USERCHANGE 2\n",
    "\n",
    "# Find the index where the new date should be inserted\n",
    "insert_index = bisect.bisect_left(date_list, date_to_add)\n",
    "\n",
    "# Insert the new date at the calculated index\n",
    "date_list.insert(insert_index, date_to_add)\n",
    "                 \n",
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3d816-46f2-4135-b987-434b04749d64",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "Information about the shape can be extracted from ifgs.res files and are denoted using 'nlines' and 'npixels', respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1aa081-d05d-4203-92f5-72e3af9c1e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the metadata ifgs.res file\n",
    "\n",
    "filepath = str(path) + '/' + 'process_StEustatius_fixed_mtiming_dembased_20180117/' + date_list[0] + '/ifgs.res'\n",
    "\n",
    "with open(filepath, 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "# Look through DORIS V5 'ifgs.res' file for shape\n",
    "\n",
    "lines = r'Number of lines \\(multilooked\\):\\s+(\\d+)'\n",
    "pixels = r'Number of pixels \\(multilooked\\):\\s+(\\d+)'\n",
    "match_lines = re.search(lines, content)\n",
    "match_pixels = re.search(pixels, content)\n",
    "\n",
    "if match_lines:\n",
    "    \n",
    "    # Extract the number of lines from the matched pattern\n",
    "    \n",
    "    num_lines = int(match_lines.group(1))\n",
    "    print(f\"Number of lines: {num_lines}\")\n",
    "else:\n",
    "    print(\"Not found in the file.\")\n",
    "\n",
    "if match_pixels:\n",
    "    \n",
    "    # Extract the number of pixels from the matched pattern\n",
    "    \n",
    "    num_pixels = int(match_pixels.group(1))\n",
    "    print(f\"Number of pixels: {num_pixels}\")\n",
    "else:\n",
    "    print(\"Not found in the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3712c1-9c62-4dfd-847e-f081eebfa758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape=(num_lines, num_pixels)  # obtained from ifgs.res --> nlines= rows ; npixels = columns\n",
    "dtype = np.dtype([('re', np.float32), ('im', np.float32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282f092-5c78-435f-983b-e886601e4bd7",
   "metadata": {},
   "source": [
    "### Loading the raw interferogram into a `xarray.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c9644-e54c-4d47-9903-58cb647df1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create xarray.Dataset object from .raw file\n",
    "\n",
    "ifg_stack = sarxarray.from_binary(list_ifgs, shape, dtype=dtype)\n",
    "\n",
    "ifg_stack = ifg_stack.chunk({\"azimuth\":500, \"range\":500, \"time\":1 })  # set custom chunk sizes\n",
    "ifg_stack.complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14809620-038e-42d5-8dba-184e56a71574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(ifg_stack.phase.isel(time=5))\n",
    "ifg_stack.phase.isel(time=5).plot(robust=True, cmap='jet')  # cmap='jet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89b718-dae1-4562-96a3-89429d083afa",
   "metadata": {},
   "source": [
    "### Pair Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152eb6c9-b651-4244-9937-a03cdbabce68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = open(\"data_alos2_seus_p36/process_StEustatius_fixed_mtiming_dembased_20180117/baselines_alos2_p36_20180117.txt\")   # USERCHANGE 6\n",
    "\n",
    "metadata = metadata.readlines()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fa103-f7df-4bee-9ced-f593fb641738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_perp = []\n",
    "B_date = []\n",
    "date_list = []\n",
    "\n",
    "for i in range(len(metadata)):\n",
    "    split_string = metadata[i].split()\n",
    "    split_string_subset = metadata[i].split('/')[0]\n",
    "    \n",
    "    date_list.append(split_string_subset)\n",
    "    B_perp.append(float(split_string[3]))\n",
    "    B_date.append(split_string_subset)\n",
    "    \n",
    "format = '%Y%m%d'\n",
    "\n",
    "B_T = []\n",
    "for i in B_date:\n",
    "    formatted = datetime.strptime(i, format)\n",
    "    B_T.append(formatted.date())\n",
    "    \n",
    "# Remove the mother value (BL = 0)\n",
    "B_perp_original = B_perp.copy()\n",
    "\n",
    "idx_remove = B_perp.index(0.0)\n",
    "B_perp.pop(idx_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc267376-5c59-4c70-8fb3-c6b54cea0e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate spatio-temporal baselines for all possible combinations\n",
    "\n",
    "def B_combinations(B_perp, B_T, date_list, idx_remove):\n",
    "    \n",
    "    # Baselines (Bms_perp & Bms_T) for all the unique combinations\n",
    "\n",
    "    B_perp_combo = []\n",
    "    B_T_combo = []\n",
    "    date_list_combo = []\n",
    "    \n",
    "    for i in range(len(B_T)):\n",
    "        for j in range(len(B_T)):\n",
    "            if(j > i): \n",
    "                t_combo = (B_T[i]-B_T[j])\n",
    "                B_T_combo.append(t_combo.days)\n",
    "                \n",
    "                date_combo = (date_list[i] + '-' + date_list[j])\n",
    "                date_list_combo.append(date_combo)\n",
    "\n",
    "    for i in range(len(B_perp)):\n",
    "        for j in range(len(B_perp)):\n",
    "            if(i > j):\n",
    "                perp_combo = B_perp[i] - B_perp[j]\n",
    "                B_perp_combo.append(perp_combo)\n",
    "            \n",
    "    # Combine with original list to get all possible combinations (+ original)\n",
    "    \n",
    "    B_perp_comp = B_perp_combo.copy()\n",
    "    B_perp_comp[idx_remove:idx_remove] = B_perp\n",
    "        \n",
    "    return B_perp_comp, B_T_combo, date_list_combo, t_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c5d91-14fe-4d58-9845-cf463f82abc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mod_coh(B_perp, B_T, B_perp_max, B_T_max):\n",
    "    coh_modelled = max((1 - (np.abs(B_perp)/B_perp_max)),0) * max((1 - (np.abs(B_T)/B_T_max)),0)\n",
    "    return coh_modelled\n",
    "\n",
    "# if both negative ; should not be taken into account --> 0 per element;\n",
    "# for now linear behaviour, could be refined to have quadratic e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d0666-6bd8-478a-9e04-a07ef4be389b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_perp_comp, B_T_comp,date_list_combo,t_combo = B_combinations(B_perp, B_T, date_list, idx_remove)\n",
    "len(B_T_comp)\n",
    "\n",
    "coh_modelled = []\n",
    "for i in range(len(B_perp_comp)):\n",
    "    coh = mod_coh(B_perp_comp[i], B_T_comp[i],  14500, 1152)\n",
    "    coh_modelled.append(coh)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd484d9-a852-4ae0-8974-528ba001908b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pair selection algorithm\n",
    "\n",
    "selection_idx = [i for i, val in enumerate(coh_modelled) if val > 0.3]\n",
    "\n",
    "pair_selection = []\n",
    "B_perp_sel = []\n",
    "B_T_sel = []\n",
    "for i in selection_idx:\n",
    "    selection = date_list_combo[i]\n",
    "    pair_selection.append(selection)\n",
    "    \n",
    "len(pair_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac7854-4028-4b30-bb57-2aa7241cf924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pair_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ad9d7-97d8-4c51-943c-045420ef5438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot baseline configuration PSI\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(B_T,B_perp_original, marker='^',zorder=2, color=['red' if i==0 else 'blue' for i in B_perp_original])\n",
    "\n",
    "for i in range(len(B_T)):\n",
    "    if B_perp_original[i] == 0:\n",
    "        for j in range(len(B_T)):\n",
    "            if i != j and B_perp_original[j] != 0:\n",
    "                plt.plot([B_T[i], B_T[j]], [B_perp_original[i], B_perp_original[j]], color='grey', linestyle='-',linewidth=0.5, zorder=1)\n",
    "\n",
    "# Set the x-axis label format\n",
    "\n",
    "date_formatter = DateFormatter('%b %Y')  # Format: Month Year\n",
    "plt.gca().xaxis.set_major_formatter(date_formatter)\n",
    "\n",
    "# Set the x-axis tick locator\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(DayLocator(interval=200))\n",
    "\n",
    "plt.grid()\n",
    "plt.title('ALOS-2 p36 St.Eustatius - Single-Mother Configuration')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Perpendicular Baseline [m]')\n",
    "# plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd84ba6-208f-4924-8575-965005c9cc29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot baseline configuration SBAS\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(B_T,B_perp_original, marker='^',zorder=2, color=['red' if i==0 else 'blue' for i in B_perp_original])\n",
    "\n",
    "# Connect lines between the pair selection result\n",
    "\n",
    "start = []\n",
    "end = []\n",
    "for pair in pair_selection:\n",
    "    start_date, end_date = pair.split('-')[0], pair.split('-')[1]\n",
    "    start_date = datetime.strptime(start_date, '%Y%m%d').date()\n",
    "    end_date = datetime.strptime(end_date, '%Y%m%d').date()\n",
    "    \n",
    "    start.append(start_date)\n",
    "    end.append(end_date)\n",
    "\n",
    "for i in range(len(start)):\n",
    "    idx_i = B_T.index(start[i])\n",
    "    idx_j = B_T.index(end[i])\n",
    "    plt.plot([B_T[idx_i], B_T[idx_j]], [B_perp_original[idx_i], B_perp_original[idx_j]], color='grey', linestyle='-', linewidth=0.5, zorder=1)\n",
    "\n",
    "# Set the x-axis label format\n",
    "\n",
    "date_formatter = DateFormatter('%b %Y')  # Format: Month Year\n",
    "plt.gca().xaxis.set_major_formatter(date_formatter)\n",
    "\n",
    "# Set the x-axis tick locator\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(DayLocator(interval=365))\n",
    "\n",
    "plt.grid()\n",
    "plt.title('ALOS-2 p36 St.Eustatius - Short-Baseline Configuration')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Perpendicular Baseline [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8f700-4b6c-43e8-beef-b3944c098e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split_string_subset = pair_selection[0].split('-')[0]\n",
    "output = []\n",
    "for i in range(len(pair_selection)):\n",
    "    split_string0 = pair_selection[i].split('-')[0]\n",
    "    split_string1 = pair_selection[i].split('-')[1]\n",
    "    output.append(split_string0)\n",
    "    output.append(split_string1)\n",
    "\n",
    "unique_list = list(set(output))\n",
    "unique_list.sort()\n",
    "\n",
    "len(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c608e6-a61b-4982-99ad-931c765886e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pair_selection_dict = {}\n",
    "\n",
    "mother_str = '20180117'\n",
    "mother_idx = unique_list.index(mother_str)\n",
    "\n",
    "for pair in pair_selection:\n",
    "    \n",
    "    # Retrieve the first date from a unique and ordered list and use it as the key\n",
    "    \n",
    "    key = pair.split('-')[0]\n",
    "    index_key = date_list.index(key) ##### !!!!!!!!!!!!!!!!!!!!!!!!!!! CHANGED FROM unique_list.index to this because one data pair not combined in this case\n",
    "    \n",
    "    value_toAdd = pair.split('-')[1]\n",
    "    index_value_toAdd = date_list.index(value_toAdd) ##### !!!!!!!!!!!!!!!!!!!!!!!!!!! CHANGED FROM unique_list.index to this because one data pair not combined in this case\n",
    "    \n",
    "    if(index_key in pair_selection_dict):\n",
    "        combination_list = pair_selection_dict[index_key]\n",
    "        combination_list.append(index_value_toAdd)\n",
    "        pair_selection_dict[index_key] = combination_list\n",
    "    else:\n",
    "        pair_selection_dict[index_key] = [index_value_toAdd]\n",
    "\n",
    "pair_selection_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d0cad5-2d86-4caa-bb53-607f63de4440",
   "metadata": {},
   "source": [
    "### Interferogram Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07096cfb-5171-4044-8d7b-c6c587247be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method 2 - Phasor = total radar measurement per pixel\n",
    "\n",
    "f_mother = 'slave_rsmp.raw'  # Load complex data of mother to obtain amplitude\n",
    "\n",
    "shape=(num_lines, num_pixels)  # obtained from ifgs.res --> nlines = rows ; npixels = columns\n",
    "dtype = np.dtype([('re', np.float32), ('im', np.float32)])\n",
    "\n",
    "mother = [p for p in path.rglob('*slave_rsmp.raw')]\n",
    "mother = [p for p in mother if '20180117\\slave_rsmp.raw' in str(p)]\n",
    "mother.sort()\n",
    "mother\n",
    "\n",
    "mother = sarxarray.from_binary(mother, shape, dtype=dtype)\n",
    "mother = mother.chunk({\"azimuth\":200, \"range\":200, \"time\":1 })  # set custom chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c12c1a-6b3d-4805-8320-ae3015712bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_angle(x,y,z):\n",
    "    func = lambda x,y,z: np.angle((y*np.conj(x))/(z)**2)\n",
    "    pha = xr.apply_ufunc(func, x, y, z, dask='allowed')\n",
    "    return pha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1e731-cda0-44e4-a541-88bb603fbdd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SBAS_structure_m2(i,j):\n",
    "        \n",
    "        P0i = phasor.isel(time=i)\n",
    "        P0j = phasor.isel(time=j)\n",
    "        \n",
    "        comp = (P0i*np.conj(P0j))/(mother.amplitude)**2\n",
    "        amp = np.abs(comp)\n",
    "        phase = calc_angle(P0j,P0i,mother.amplitude)    \n",
    "        \n",
    "        stack_SBAS_combo = xr.DataArray.to_dataset(comp, dim=None, name='complex', promote_attrs=False)\n",
    "        stack_SBAS_combo['amplitude'] = amp\n",
    "        stack_SBAS_combo['phase'] = phase\n",
    "        \n",
    "        return stack_SBAS_combo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad51e3-fd47-427d-8d6c-108954df287b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PAIR SELECTION ALGORITHM\n",
    "phasor = ifg_stack.complex\n",
    "\n",
    "t_count = 0\n",
    "coords = []\n",
    "first_skip = False\n",
    "\n",
    "i_correction = 0\n",
    "j_correction = 0\n",
    "\n",
    "for i in range(len(ifg_stack.time)):\n",
    "    \n",
    "    # Check if key = i exists in dict of pairs\n",
    "    # else skip/continue\n",
    "\n",
    "    if(i not in pair_selection_dict):\n",
    "        continue\n",
    "\n",
    "    # Retrieve the list that are paired with key = i\n",
    "    pairs = pair_selection_dict[i]\n",
    "    \n",
    "    # Correction of the indexes after the mother_idx\n",
    "    j_correction = 0 # correction for the j has to reset after every i-loop\n",
    "    if(i > mother_idx):\n",
    "        i_correction = 1\n",
    "\n",
    "    for j in pairs:\n",
    "        \n",
    "        if(j > mother_idx):\n",
    "            j_correction = 1\n",
    "        \n",
    "        # mother check\n",
    "        if(i == mother_idx):\n",
    "            toAdd = ifg_stack.isel(time=j-j_correction)  # CHANGE THIS LINE TO GET CORRECT IFG GET i if mother =j and vice versa.\n",
    "        elif(j == mother_idx):\n",
    "            toAdd = ifg_stack.isel(time=i-i_correction)\n",
    "        else:\n",
    "            toAdd = SBAS_structure_m2(i-i_correction,j-j_correction)\n",
    "\n",
    "         # If count is zero, create initial stack_SBAS_combo, else concat to stack_SBAS_combo \n",
    "        if(t_count == 0):\n",
    "            stack_SBAS_combo = toAdd\n",
    "        else:\n",
    "            stack_SBAS_combo = xr.concat([stack_SBAS_combo, toAdd], \"time\")\n",
    "            \n",
    "        coords.append(t_count)\n",
    "        t_count+=1\n",
    "\n",
    "stack_SBAS_combo = stack_SBAS_combo.assign_coords(time=coords)\n",
    "\n",
    "stack_SBAS_combo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f390bee-eaef-48e5-bbea-340f0e2746ce",
   "metadata": {},
   "source": [
    "### Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b5b46-eba1-41d8-b20a-e4dfd96e17f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coherence = magnitude of an ifg pixels/product of the magnitudes of the original imageâ€™s pixels.\n",
    "\n",
    "f_mother = 'slave_rsmp.raw'  # Load complex data of mother to obtain amplitude\n",
    "\n",
    "shape=(num_lines, num_pixels)  # obtained from ifgs.res --> nlines = rows ; npixels = columns\n",
    "dtype = np.dtype([('re', np.float32), ('im', np.float32)])\n",
    "\n",
    "list_daughters = [p for p in path.rglob('*slave_rsmp.raw')]\n",
    "list_daughters.sort()\n",
    "\n",
    "# # Path to remove\n",
    "\n",
    "path_to_mother_rsmp = Path('caroline/Share/projects/antilles/stacks/alos2/alos2_sm3_p36_f340/process_StEustatius_fixed_mtiming_dembased/process_StEustatius_fixed_mtiming_dembased_20180117/20180117/slave_rsmp.raw')\n",
    "\n",
    "# # Convert path_to_remove to a string\n",
    "\n",
    "string_to_remove = str(path_to_mother_rsmp)\n",
    "\n",
    "# # Filter out the path based on the string\n",
    "\n",
    "list_daughters = [path for path in list_daughters if str(path) != string_to_remove]\n",
    "list_daughters\n",
    "\n",
    "daughters_stack = sarxarray.from_binary(list_daughters, shape, dtype=dtype)\n",
    "daughters_stack = daughters_stack.chunk({\"azimuth\":200, \"range\":200, \"time\":1 })  # set custom chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d3bff-c6b6-45e1-921e-46f8023610c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Slice the daughters_stack data array into two parts along the t-dim\n",
    "\n",
    "daughters_stack_before = daughters_stack.isel(time=slice(None, mother_idx))\n",
    "daughters_stack_after = daughters_stack.isel(time=slice(mother_idx, None))\n",
    "\n",
    "# Concatenate the two parts with the mother data\n",
    "\n",
    "daughter_mother_stack_sub = xr.concat([daughters_stack_before, mother],dim=\"time\")\n",
    "daughter_mother_stack = xr.concat([daughter_mother_stack_sub, daughters_stack_after],dim=\"time\")\n",
    "daughter_mother_stack = daughter_mother_stack.assign_coords(time=np.arange(0,len(daughters_stack.time)+1,1))\n",
    "daughter_mother_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccd076-16f0-4fa8-b0d4-378a4634a6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find zeros in the daughter_mother_stack and alter zero_replacement accordingly\n",
    "\n",
    "zero_replacement = 0.01\n",
    "\n",
    "for t in range(len(daughter_mother_stack.time)):\n",
    "    if (daughter_mother_stack.isel(time=t).amplitude == 0).any(dim=(\"azimuth\", \"range\")):\n",
    "        print(f\"mother.amplitude contains zero values for time {t}.\")\n",
    "        \n",
    "        # Get the amplitude values for each t-dim\n",
    "        amplitude_values = daughter_mother_stack[\"amplitude\"].isel(time=t).values\n",
    "        \n",
    "        # Replace zeros with the set replacement value\n",
    "        amplitude_values[amplitude_values == 0] = zero_replacement\n",
    "        # print(daughter_mother_stack[\"amplitude\"][t, :, :].shape)\n",
    "        \n",
    "        # Update the dataset\n",
    "        daughter_mother_stack.amplitude.loc[dict(time=t)] = amplitude_values\n",
    "    else:\n",
    "        print(f\"No zeros found for time {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead08a7-d263-4366-85e6-de0c54d6362d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moving_average(data, N):\n",
    "    \n",
    "    # Determine the number of rows & columns in the output raster\n",
    "    \n",
    "    nrows = shape[0] - N[0] + 1\n",
    "    ncols = shape[1] - N[1] + 1\n",
    "    \n",
    "    # Specify a different window size in x and y direction\n",
    "    window_size = (22,8)\n",
    "\n",
    "    # Apply the uniform filter\n",
    "    filtered_arr = uniform_filter(data, size=window_size)\n",
    "    \n",
    "    return filtered_arr, nrows, ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a09b7a-2844-403e-9c3b-ad30b33a31f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_mags_SLC(SLC_data, windowsize):\n",
    "        av_mag_SLC = []      \n",
    "        \n",
    "        for i in range(len(SLC_data.time)):\n",
    "            mag_A_i, nrows, ncols = moving_average((SLC_data.amplitude.isel(time=i).values)**2, windowsize)\n",
    "            av_mag_SLC.append(mag_A_i)\n",
    "        \n",
    "        return av_mag_SLC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83906ba7-9482-4b66-89a4-9414d20de1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_mav_ifg(ifg_data, windowsize):\n",
    "        av_I = []      \n",
    "        \n",
    "        for i in range(len(ifg_data.time)):\n",
    "            \n",
    "            # calculate moving average of the combinations\n",
    "            mag_I_count, nrows_I, ncols_I = moving_average(ifg_data.complex.isel(time=i).values, windowsize)\n",
    "            av_I.append(mag_I_count)\n",
    "        \n",
    "        return av_I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3e630-5814-443f-8be3-5c23520560e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This code needs to run once\n",
    "\n",
    "# Calculate mag for all the 11 times\n",
    "av_mag_SLC = calc_mags_SLC(daughter_mother_stack, np.array([22,8]))\n",
    "\n",
    "# Calculate mag for all the 32 times\n",
    "av_I = calc_mav_ifg(stack_SBAS_combo, np.array([22,8]))\n",
    "\n",
    "# Create initial data variables\n",
    "av_I_first, nrows_first, ncols_first = moving_average(stack_SBAS_combo.complex.isel(time=0).values, np.array([22,8]))\n",
    "first_coh = np.abs(av_I_first/(np.sqrt(av_mag_SLC[0]) * np.sqrt(av_mag_SLC[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f220daa-d8d6-41cb-b1b7-c6a0fb01c0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# New coherence\n",
    "\n",
    "def calc_coherence(first_coh, it_length, av_I, av_Ai, nrows, ncols, date_list):\n",
    "\n",
    "    #################################################################\n",
    "    # INPUT:\n",
    "    # first_coh = first coherence I01, to set up xarray datastructure\n",
    "    # av_I = phasor (ifg.complex) post moving average\n",
    "    # av_A0 = original amplitude SLC's post moving average\n",
    "    \n",
    "    # OUTPUT:\n",
    "    # coh_combo_stack = coherence ALL possible combo's [numpy array]\n",
    "    #################################################################\n",
    "    \n",
    "    # prepare list with dates; start by filling first one\n",
    "    \n",
    "    date_title = []\n",
    "    \n",
    "    first_date = date_list[0] + '-' + date_list[1]\n",
    "    date_title.insert(0, first_date)\n",
    "    \n",
    "    # Create data array\n",
    "    shape_subset = daughter_mother_stack.dims['azimuth'],daughter_mother_stack.dims['range']\n",
    "    coh_combo_stack = xr.DataArray(first_coh, \n",
    "                            coords={'azimuth': np.arange(0,shape_subset[0], 1, dtype=int),\n",
    "                            'range': np.arange(0, shape_subset[1], 1, dtype=int)}, \n",
    "                            dims=[\"azimuth\",\"range\"])\n",
    "    count = 1\n",
    "    coords = []\n",
    "    coords.append(count-1)\n",
    "    \n",
    "    first_skipped = False\n",
    "    \n",
    "    \n",
    "#     for i in range(len(pair_selection_dict)):\n",
    "    for i in pair_selection_dict:\n",
    "        pairs = pair_selection_dict[i]\n",
    "        for j in pairs:\n",
    "            \n",
    "            # check to skip combinations with the same time and only do unique combinations\n",
    "            if(j > i):\n",
    "                   \n",
    "                # first is already present\n",
    "                if(first_skipped):\n",
    "                    \n",
    "#                     # calculate mag of the combinations\n",
    "#                     mag_I_count, nrows_I, ncols_I = moving_average(stack_SBAS_combo.amplitude.isel(time=count).values, np.array([20,4]))\n",
    "\n",
    "                    # calc coh\n",
    "                    coherence = np.abs(av_I[count])/(np.sqrt(av_Ai[i]) * np.sqrt(av_Ai[j]))\n",
    "        \n",
    "                    # prep date titles\n",
    "                    date = date_list[i] + '-' + date_list[j]\n",
    "                    date_title.append(date)\n",
    "                    # date_title = 0\n",
    "            \n",
    "                    # add no data values to obtain same size as input shape\n",
    "                    coh_toAdd = np.zeros((shape_subset[0],shape_subset[1]))\n",
    "                    coh_toAdd[:] = np.nan\n",
    "                    coh_toAdd[0:coherence.shape[0], 0:coherence.shape[1]] = coherence\n",
    "                    \n",
    "                    # convert to data-array structure\n",
    "                    coh_toAdd = xr.DataArray(coh_toAdd, \n",
    "                            coords={'azimuth': np.arange(0, shape_subset[0], 1, dtype=int),\n",
    "                            'range': np.arange(0, shape_subset[1], 1, dtype=int)}, \n",
    "                            dims=[\"azimuth\",\"range\"])\n",
    "            \n",
    "                    # Add coh to the data-array\n",
    "                    coh_combo_stack = xr.concat([coh_combo_stack, coh_toAdd], dim=\"time\")\n",
    "                    \n",
    "\n",
    "                    # Go to the next combination\n",
    "                    coords.append(count)\n",
    "                    count+=1    \n",
    "                    \n",
    "                # Make true after the first combination: i=0, j=1\n",
    "                first_skipped = True\n",
    "    \n",
    "    coh_combo_stack = coh_combo_stack.astype(np.float32)\n",
    "    coh_combo_stack = coh_combo_stack.assign_coords(time=coords)\n",
    "    coh_combo_stack = xr.DataArray.to_dataset(coh_combo_stack, dim=None, name='coherence', promote_attrs=False)\n",
    "    \n",
    "    return coh_combo_stack, date_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e8677-1bf5-43c2-b5ca-c32ef8cb68c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coh_combo_stack, date_title = calc_coherence(first_coh, len(pair_selection_dict), av_I, av_mag_SLC, nrows_first, ncols_first, date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad0d31-d7b7-4612-8b7a-12fb31fa0451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.nanmax(coh_combo_stack.coherence.isel(time=0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf205ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = coh_combo_stack['coherence'].isel(time=0).argmax(['azimuth', 'range'])\n",
    "int(max_idx['azimuth'].values), int(max_idx['range'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac7a87-2173-42b8-9adf-73d2b3f0fc94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first_coh = np.abs(av_I_first/(np.sqrt(av_mag_SLC[0]) * np.sqrt(av_mag_SLC[1])))\n",
    "\n",
    "np.abs(av_I[0][int(max_idx['azimuth'].values),int(max_idx['range'].values)])/(np.sqrt(av_mag_SLC[0][int(max_idx['azimuth'].values),int(max_idx['range'].values)])*np.sqrt(av_mag_SLC[1][int(max_idx['azimuth'].values),int(max_idx['range'].values)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d3c23-d157-43d0-8d14-f93361100a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(coh_combo_stack.coherence.isel(time=1))\n",
    "coh_combo_stack.coherence.isel(time=1).plot(robust=True, cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56336e-5dbc-41ca-aaaf-920c9b24d8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(coh_combo_stack.coherence.isel(time=0).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ecc66-a052-4f3c-881a-69e48bf32349",
   "metadata": {},
   "source": [
    "### Create interferograms from SLC's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b15e05-924c-4339-8408-2c77c747fe02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_angle(x,y):\n",
    "    func = lambda x,y: np.angle((y*np.conj(x)))\n",
    "    pha = xr.apply_ufunc(func, x, y, dask='allowed')\n",
    "    return pha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a48c2-8706-4b58-96a7-c6aa05933584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P_mother = mother.complex.isel(time=0)\n",
    "\n",
    "t_count = 0\n",
    "for i in range(len(daughters_stack.time)):\n",
    "    \n",
    "    P_daughter = daughters_stack.complex.isel(time=i)\n",
    "\n",
    "    comp = P_mother*np.conj(P_daughter)\n",
    "    amp = np.abs(comp)\n",
    "    phase = calc_angle(P_daughter,P_mother)\n",
    "   \n",
    "    stack_compare = xr.DataArray.to_dataset(comp, dim=None, name='complex', promote_attrs=False)\n",
    "    stack_compare['amplitude'] = amp\n",
    "    stack_compare['phase'] = phase\n",
    "    \n",
    "    stack_compare.coords['time'] = ('time', [i])\n",
    "    \n",
    "    if t_count == 0:\n",
    "        ifg_stack_compare = stack_compare\n",
    "    else:\n",
    "        ifg_stack_compare = xr.concat([ifg_stack_compare, stack_compare], \"time\")\n",
    "        \n",
    "    t_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifg_stack_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee2653-de57-412e-be7c-62c4ec1b9423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using cint_srd from Doris\n",
    "\n",
    "plt.imshow(ifg_stack.amplitude.isel(time=0))\n",
    "ifg_stack.amplitude.isel(time=0).plot(robust=True, cmap='jet')  # cmap='jet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb844d8-8a8d-4d5b-b66e-39043dafdc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using SLC's from Doris\n",
    "\n",
    "plt.imshow(ifg_stack_compare.amplitude.isel(time=0))\n",
    "ifg_stack_compare.amplitude.isel(time=0).plot(robust=True, cmap='jet')  # cmap='jet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab07e9-87b0-4dda-8a81-08328b2a3737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff_amp = ifg_stack_compare.amplitude.isel(time=0) - ifg_stack.amplitude.isel(time=0)\n",
    "\n",
    "plt.imshow(diff_amp)\n",
    "diff_amp.plot(robust=True, cmap='jet')  # cmap='jet\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb9249",
   "metadata": {},
   "source": [
    "**Repeat steps to calculate new SBAS combinations & corresponding coherence** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449a4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_angle(x,y,z):\n",
    "    func = lambda x,y,z: np.angle((y*np.conj(x))/(z)**2)\n",
    "    pha = xr.apply_ufunc(func, x, y, z, dask='allowed')\n",
    "    return pha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afce7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAIR SELECTION ALGORITHM\n",
    "phasor = ifg_stack_compare.complex\n",
    "\n",
    "t_count = 0\n",
    "coords = []\n",
    "first_skip = False\n",
    "\n",
    "i_correction = 0\n",
    "j_correction = 0\n",
    "\n",
    "for i in range(len(ifg_stack_compare.time)):\n",
    "    \n",
    "    # Check if key = i exists in dict of pairs\n",
    "    # else skip/continue\n",
    "\n",
    "    if(i not in pair_selection_dict):\n",
    "        continue\n",
    "\n",
    "    # Retrieve the list that are paired with key = i\n",
    "    pairs = pair_selection_dict[i]\n",
    "    \n",
    "    # Correction of the indexes after the mother_idx\n",
    "    j_correction = 0 # correction for the j has to reset after every i-loop\n",
    "    if(i > mother_idx):\n",
    "        i_correction = 1\n",
    "\n",
    "    for j in pairs:\n",
    "        \n",
    "        if(j > mother_idx):\n",
    "            j_correction = 1\n",
    "        \n",
    "        # mother check\n",
    "        if(i == mother_idx):\n",
    "            toAdd = ifg_stack_compare.isel(time=j-j_correction)  # CHANGE THIS LINE TO GET CORRECT IFG GET i if mother =j and vice versa.\n",
    "        elif(j == mother_idx):\n",
    "            toAdd = ifg_stack_compare.isel(time=i-i_correction)\n",
    "        else:\n",
    "            toAdd = SBAS_structure_m2(i-i_correction,j-j_correction)\n",
    "\n",
    "         # If count is zero, create initial stack_SBAS_combo, else concat to stack_SBAS_combo \n",
    "        if(t_count == 0):\n",
    "            stack_SBAS_combo_compare = toAdd\n",
    "        else:\n",
    "            stack_SBAS_combo_compare = xr.concat([stack_SBAS_combo_compare, toAdd], \"time\")\n",
    "            \n",
    "        coords.append(t_count)\n",
    "        t_count+=1\n",
    "\n",
    "stack_SBAS_combo_compare = stack_SBAS_combo_compare.assign_coords(time=coords)\n",
    "\n",
    "stack_SBAS_combo_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcb5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This code needs to run once\n",
    "\n",
    "# Calculate mag for all the 11 times\n",
    "av_mag_SLC = calc_mags_SLC(daughter_mother_stack, np.array([22,8]))\n",
    "\n",
    "# Calculate mag for all the 32 times\n",
    "av_I = calc_mav_ifg(stack_SBAS_combo_compare, np.array([22,8]))\n",
    "\n",
    "# Create initial data variables\n",
    "av_I_first, nrows_first, ncols_first = moving_average(stack_SBAS_combo_compare.complex.isel(time=0).values, np.array([22,8]))\n",
    "first_coh = np.abs(av_I_first/(np.sqrt(av_mag_SLC[0]) * np.sqrt(av_mag_SLC[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3aeea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coh_combo_stack, date_title = calc_coherence(first_coh, len(pair_selection_dict), av_I, av_mag_SLC, nrows_first, ncols_first, date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88deed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.nanmax(coh_combo_stack.coherence.isel(time=0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d522936",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = coh_combo_stack['coherence'].isel(time=0).argmax(['azimuth', 'range'])\n",
    "int(max_idx['azimuth'].values), int(max_idx['range'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd2ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first_coh = np.abs(av_I_first/(np.sqrt(av_mag_SLC[0]) * np.sqrt(av_mag_SLC[1])))\n",
    "\n",
    "np.abs(av_I[0][int(max_idx['azimuth'].values),int(max_idx['range'].values)])/(np.sqrt(av_mag_SLC[0][int(max_idx['azimuth'].values),int(max_idx['range'].values)])*np.sqrt(av_mag_SLC[1][int(max_idx['azimuth'].values),int(max_idx['range'].values)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d659785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(coh_combo_stack.coherence.isel(time=1))\n",
    "coh_combo_stack.coherence.isel(time=1).plot(robust=True, cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcccf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(coh_combo_stack.coherence.isel(time=0).values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
