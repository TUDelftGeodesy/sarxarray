{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SARXarray","text":"<p>SARXarray is an open-source Xarray extension for Synthetic Aperture Radar (SAR) data.</p> <p>SARXarray is especially designed to work with complex data, that is, containing both the phase and amplitude of the data. The extension can handle coregistered stacks of Single Look Complex (SLC) data, as well as derived products such as interferogram stacks. It utilizes Xarray\u2019s support on labeled multi-dimensional datasets to stress the space-time character of the image stacks. Dask Array is implemented to support parallel computation.</p> <p>SARXarry supports the following functionalities:</p> <ol> <li> <p>Chunk-wise reading/writing of coregistered SLC or interferogram stacks;</p> </li> <li> <p>Basic operations on complex data, e.g., averaging along axis and complex conjugate multiplication;</p> </li> <li> <p>Specific SAR data operations, e.g., multilooking and coherence estimation.</p> </li> </ol> <p>All the above functionalities can be scaled up to a Hyper-Performance Computation (HPC) system.</p>"},{"location":"setup/","title":"Installation","text":"<p>SARXarray can be installed from PyPI:</p> <pre><code>pip install sarxarray\n</code></pre> <p>or from the source:</p> <pre><code>git clone git@github.com:MotionbyLearning/sarxarray.git\ncd sarxarray\npip install .\n</code></pre> <p>Note that Python version <code>&gt;3.10</code> is required for SARXarray.</p>"},{"location":"setup/#tips","title":"Tips","text":"<p>We strongly recommend installing separately from your default Python envrionment. E.g. you can use enviroment manager e.g. conda to create separate environment.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#input-data-format","title":"Input data format","text":"<p>SARXarry works with corregitserred SLC / interferogram stack. Conventionally they are provided in binary format. SARXarry provides a reader to perform lazy loading on a binary stack. However, we recommend to store the corregitserred stack in <code>zarr</code> format, and directly load them as an Xarray object by <code>xarray.open_zarr</code>. </p>"},{"location":"usage/#loading-corregisterred-slc-stack-in-binary-format","title":"Loading corregisterred SLC stack in binary format","text":"<p>If the stack is saved in binary fomat, it can be read by <code>SARXarray</code> under two prerequisites:</p> <ol> <li>All SLCs/interferograms have the same known raster size and data type;</li> <li>All SLCs/interferograms have been resampled to the same raster grid.</li> </ol> <p>For example, let's consider a case of an stack with three SLCs:</p> <pre><code>import numpy as np\nlist_slcs = ['data/slc_1.raw', 'data/slc_2.raw', 'data/slc_3.raw']\nshape = (10018, 68656) # (azimuth, range)\ndtype = np.complex64\n</code></pre> <p>We built a list <code>list_slcs</code> with the paths to the SLCs. In this case they are stored in the same directory called <code>data</code>. The shape of each SLC is known: <code>10018</code> pixels in <code>azimuth</code> direction, and <code>68656</code> in range direction. The data type is <code>numpy.complex64</code>.</p> <p>The corregisterred SLC stack can be read using <code>from_binary</code> function:</p> <pre><code>import sarxarray\n\nstack = sarxarray.from_binary(list_slcs, shape, dtype=dtype)\n</code></pre> <p>You can also skip the <code>dtype</code> argument since it's defaulted to <code>np.complex64</code>. The stack will be read as an <code>xarray.Dataset</code> object, with data variables lazily loaded as <code>Dask Array</code>:</p> <pre><code>print(stack)\n\n&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 10018, range: 68656, time: 3)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 ... 10013 10014 10015 10016 10017\n  * range      (range) int64 0 1 2 3 4 5 ... 68650 68651 68652 68653 68654 68655\n  * time       (time) int64 0 1 2\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n</code></pre> <p>The loading chunk size can also be specified manually:</p> <pre><code>stack_smallchunk = sarxarray.from_binary(list_slcs, shape, chunks=(2000, 2000))\n</code></pre>"},{"location":"usage/#common-processing-on-an-slc-stack","title":"Common processing on an SLC stack","text":"<p>Common SAR processings can be performed by SARXarray. Below are some examples:</p>"},{"location":"usage/#multi-look","title":"Multi-look","text":"<p>Multi-look by a windowsize, e.g. 2 in azimuth dimension and 4 in range dimension:</p> <pre><code>stack_multilook = stack.slcstack.multi_look((2,4))\n</code></pre>"},{"location":"usage/#coherence","title":"Coherence","text":"<p>Compute coherence between two SLCs:</p> <pre><code>slc1 = stack.isel(time=[0]) # first image\nslc2 = stack.isel(time=[2]) # third image\nwindow = (4,4)\n\ncoherence = slc1.slcstack.complex_coherence(slc2, window)\n</code></pre>"},{"location":"usage/#mean-reflection-map-mrm","title":"Mean-Reflection-Map (MRM)","text":"<pre><code>mrm = stack_multilook.slcstack.mrm()\n</code></pre> <pre><code>from matplotlib import pyplot as plt\nfig, ax = plt.subplots()\nax.imshow(mrm)\nmrm.plot(ax=ax, robust=True, cmap='gray')\n</code></pre>"},{"location":"usage/#point-selection","title":"Point selection","text":"<p>A selection based on temporal properties per pixel can be performed. For example, we can select the Persistent Scatters (PS) by temporal dispersion of <code>amplitude</code>:</p> <pre><code>ps = stack.slcstack.point_selection(threshold=0.25, method=\"amplitude_dispersion\")\n</code></pre>"},{"location":"usage/#manipulate-an-slc-stack-as-an-xarray","title":"Manipulate an SLC stack as an Xarray","text":"<p>The loaded stack can be manipulated as an <code>Xarray.Dataset</code> instance.</p> <p>Slice the SLC stack in 3D:</p> <pre><code>stack.isel(azimuth=range(1000,2000), range=range(1500,2500), time=range(2,5))\n</code></pre> <p>Select <code>amplitude</code> attributes</p> <pre><code>amp = stack['amplitude']\n</code></pre> <p>Compute stack and peresist in memory:</p> <pre><code>stack = stack.compute()\n</code></pre>"},{"location":"notebooks/demo_sarxarray/","title":"Example Jupyter Notebook","text":"<p>In this Jupyter Notebook, we demonstrate the following operations using <code>sarxarray</code>:</p> <ul> <li>Load an SLC stack in binary format into a <code>xarray.Dataset</code> object;</li> <li>Append lat and lon coordinates;</li> <li>Create an MRM of a subset of the SLC stack;</li> <li>Apply point selection to a subset of the SLC stack;</li> <li>Export the selection results in Zarr format</li> </ul> In\u00a0[1]: Copied! <pre>import numpy as np\nfrom pathlib import Path\nimport sarxarray\n</pre> import numpy as np from pathlib import Path import sarxarray <p>We will load a interferogram stack, which has been corregistered and saved as binary files. In this example we will demo 3 interferograms with a <code>(azimuth, range)</code> coverage of <code>(9914, 41174)</code>. We assume the shape and data type is known.</p> In\u00a0[2]: Copied! <pre># Path to the interferogram dataset\n# path = Path(cwd / 'data/nl_amsterdam_s1_asc_t088')\npath = Path('../../data/nl_amsterdam_s1_asc_t088')\n\n# Make a list of SLCs to read\nf_slc = 'cint_srd.raw'\nlist_slcs = [p for p in path.rglob('*_cint_srd.raw')]\nlist_slcs.sort()\n\n# Metadata of the stack, assume known.\nshape=(2000, 4000)\n\n# Define reading chunks\nreading_chunks = (500,500)\n\nlist_slcs\n</pre> # Path to the interferogram dataset # path = Path(cwd / 'data/nl_amsterdam_s1_asc_t088') path = Path('../../data/nl_amsterdam_s1_asc_t088')  # Make a list of SLCs to read f_slc = 'cint_srd.raw' list_slcs = [p for p in path.rglob('*_cint_srd.raw')] list_slcs.sort()  # Metadata of the stack, assume known. shape=(2000, 4000)  # Define reading chunks reading_chunks = (500,500)  list_slcs Out[2]: <pre>[PosixPath('../../data/nl_amsterdam_s1_asc_t088/20180920_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20180926_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181002_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181008_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181014_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181020_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181026_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181101_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181107_cint_srd.raw'),\n PosixPath('../../data/nl_amsterdam_s1_asc_t088/20181113_cint_srd.raw')]</pre> <p>Now we perform a lazy loading of the stack</p> In\u00a0[3]: Copied! <pre># Load complex data\nstack = sarxarray.from_binary(list_slcs, shape, dtype=np.complex64, chunks=reading_chunks)\nstack\n</pre> # Load complex data stack = sarxarray.from_binary(list_slcs, shape, dtype=np.complex64, chunks=reading_chunks) stack Out[3]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 2000, range: 4000, time: 10)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * range      (range) int64 0 1 2 3 4 5 6 ... 3994 3995 3996 3997 3998 3999\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>azimuth: 2000</li><li>range: 4000</li><li>time: 10</li></ul></li><li>Coordinates: (3)<ul><li>azimuth(azimuth)int640 1 2 3 4 ... 1996 1997 1998 1999<pre>array([   0,    1,    2, ..., 1997, 1998, 1999])</pre></li><li>range(range)int640 1 2 3 4 ... 3996 3997 3998 3999<pre>array([   0,    1,    2, ..., 3997, 3998, 3999])</pre></li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li></ul></li><li>Data variables: (3)<ul><li>complex(azimuth, range, time)complex64dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   610.35 MiB   1.91 MiB   Shape   (2000, 4000, 10)   (500, 500, 1)   Dask graph   320 chunks in 709 graph layers   Data type   complex64 numpy.ndarray  10 4000 2000 </li><li>amplitude(azimuth, range, time)float32dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   305.18 MiB   0.95 MiB   Shape   (2000, 4000, 10)   (500, 500, 1)   Dask graph   320 chunks in 712 graph layers   Data type   float32 numpy.ndarray  10 4000 2000 </li><li>phase(azimuth, range, time)float32dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   305.18 MiB   0.95 MiB   Shape   (2000, 4000, 10)   (500, 500, 1)   Dask graph   320 chunks in 712 graph layers   Data type   float32 numpy.ndarray  10 4000 2000 </li></ul></li><li>Indexes: (3)<ul><li>azimuthPandasIndex<pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='azimuth', length=2000))</pre></li><li>rangePandasIndex<pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='range', length=4000))</pre></li><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <p>The data variable of the stack will be a <code>Dask.array</code>. For example we can take a look of <code>complex</code>, which is the complex value of the interferograms:</p> In\u00a0[4]: Copied! <pre>stack.complex\n</pre> stack.complex Out[4]: <pre>&lt;xarray.DataArray 'complex' (azimuth: 2000, range: 4000, time: 10)&gt;\ndask.array&lt;concatenate, shape=(2000, 4000, 10), dtype=complex64, chunksize=(500, 500, 1), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth  (azimuth) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * range    (range) int64 0 1 2 3 4 5 6 ... 3993 3994 3995 3996 3997 3998 3999\n  * time     (time) int64 0 1 2 3 4 5 6 7 8 9</pre>xarray.DataArray'complex'<ul><li>azimuth: 2000</li><li>range: 4000</li><li>time: 10</li></ul><ul><li>dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   610.35 MiB   1.91 MiB   Shape   (2000, 4000, 10)   (500, 500, 1)   Dask graph   320 chunks in 709 graph layers   Data type   complex64 numpy.ndarray  10 4000 2000 </li><li>Coordinates: (3)<ul><li>azimuth(azimuth)int640 1 2 3 4 ... 1996 1997 1998 1999<pre>array([   0,    1,    2, ..., 1997, 1998, 1999])</pre></li><li>range(range)int640 1 2 3 4 ... 3996 3997 3998 3999<pre>array([   0,    1,    2, ..., 3997, 3998, 3999])</pre></li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li></ul></li><li>Indexes: (3)<ul><li>azimuthPandasIndex<pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='azimuth', length=2000))</pre></li><li>rangePandasIndex<pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='range', length=4000))</pre></li><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[5]: Copied! <pre># Geo-referenced coordinates\nf_lat = [path / 'lat.raw']\nf_lon = [path / 'lon.raw']\n</pre> # Geo-referenced coordinates f_lat = [path / 'lat.raw'] f_lon = [path / 'lon.raw'] In\u00a0[6]: Copied! <pre># Load coordinates\nlat = sarxarray.from_binary(f_lat, shape, vlabel=\"lat\", dtype=np.float32, chunks=reading_chunks)\nlon = sarxarray.from_binary(f_lon, shape, vlabel=\"lon\", dtype=np.float32, chunks=reading_chunks)\nstack = stack.assign_coords(lat = ((\"azimuth\", \"range\"), lat.squeeze().lat.data), lon = ((\"azimuth\", \"range\"), lon.squeeze().lon.data))\nstack\n</pre> # Load coordinates lat = sarxarray.from_binary(f_lat, shape, vlabel=\"lat\", dtype=np.float32, chunks=reading_chunks) lon = sarxarray.from_binary(f_lon, shape, vlabel=\"lon\", dtype=np.float32, chunks=reading_chunks) stack = stack.assign_coords(lat = ((\"azimuth\", \"range\"), lat.squeeze().lat.data), lon = ((\"azimuth\", \"range\"), lon.squeeze().lon.data)) stack Out[6]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 2000, range: 4000, time: 10)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * range      (range) int64 0 1 2 3 4 5 6 ... 3994 3995 3996 3997 3998 3999\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\n    lat        (azimuth, range) float32 dask.array&lt;chunksize=(500, 500), meta=np.ndarray&gt;\n    lon        (azimuth, range) float32 dask.array&lt;chunksize=(500, 500), meta=np.ndarray&gt;\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>azimuth: 2000</li><li>range: 4000</li><li>time: 10</li></ul></li><li>Coordinates: (5)<ul><li>azimuth(azimuth)int640 1 2 3 4 ... 1996 1997 1998 1999<pre>array([   0,    1,    2, ..., 1997, 1998, 1999])</pre></li><li>range(range)int640 1 2 3 4 ... 3996 3997 3998 3999<pre>array([   0,    1,    2, ..., 3997, 3998, 3999])</pre></li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li><li>lat(azimuth, range)float32dask.array&lt;chunksize=(500, 500), meta=np.ndarray&gt;  Array   Chunk   Bytes   30.52 MiB   0.95 MiB   Shape   (2000, 4000)   (500, 500)   Dask graph   32 chunks in 71 graph layers   Data type   float32 numpy.ndarray  4000 2000 </li><li>lon(azimuth, range)float32dask.array&lt;chunksize=(500, 500), meta=np.ndarray&gt;  Array   Chunk   Bytes   30.52 MiB   0.95 MiB   Shape   (2000, 4000)   (500, 500)   Dask graph   32 chunks in 71 graph layers   Data type   float32 numpy.ndarray  4000 2000 </li></ul></li><li>Data variables: (3)<ul><li>complex(azimuth, range, time)complex64dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   610.35 MiB   1.91 MiB   Shape   (2000, 4000, 10)   (500, 500, 1)   Dask graph   320 chunks in 709 graph layers   Data type   complex64 numpy.ndarray  10 4000 2000 </li><li>amplitude(azimuth, range, time)float32dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   305.18 MiB   0.95 MiB   Shape   (2000, 4000, 10)   (500, 500, 1)   Dask graph   320 chunks in 712 graph layers   Data type   float32 numpy.ndarray  10 4000 2000 </li><li>phase(azimuth, range, time)float32dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   305.18 MiB   0.95 MiB   Shape   (2000, 4000, 10)   (500, 500, 1)   Dask graph   320 chunks in 712 graph layers   Data type   float32 numpy.ndarray  10 4000 2000 </li></ul></li><li>Indexes: (3)<ul><li>azimuthPandasIndex<pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='azimuth', length=2000))</pre></li><li>rangePandasIndex<pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999],\n      dtype='int64', name='range', length=4000))</pre></li><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[7]: Copied! <pre>stack_multilook = stack.slcstack.multi_look((1,2))\nstack_multilook\n</pre> stack_multilook = stack.slcstack.multi_look((1,2)) stack_multilook Out[7]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 2000, range: 2000, time: 10)\nCoordinates:\n  * azimuth    (azimuth) float64 0.0 1.0 2.0 ... 1.997e+03 1.998e+03 1.999e+03\n  * range      (range) float64 0.5 2.5 4.5 6.5 ... 3.994e+03 3.996e+03 3.998e+03\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\n    lat        (azimuth, range) float32 dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;\n    lon        (azimuth, range) float32 dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(1000, 1000, 10), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(1000, 1000, 10), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(1000, 1000, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>azimuth: 2000</li><li>range: 2000</li><li>time: 10</li></ul></li><li>Coordinates: (5)<ul><li>azimuth(azimuth)float640.0 1.0 2.0 ... 1.998e+03 1.999e+03<pre>array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.997e+03, 1.998e+03, 1.999e+03])</pre></li><li>range(range)float640.5 2.5 4.5 ... 3.996e+03 3.998e+03<pre>array([5.0000e-01, 2.5000e+00, 4.5000e+00, ..., 3.9945e+03, 3.9965e+03,\n       3.9985e+03])</pre></li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li><li>lat(azimuth, range)float32dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;  Array   Chunk   Bytes   15.26 MiB   3.81 MiB   Shape   (2000, 2000)   (1000, 1000)   Dask graph   4 chunks in 75 graph layers   Data type   float32 numpy.ndarray  2000 2000 </li><li>lon(azimuth, range)float32dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;  Array   Chunk   Bytes   15.26 MiB   3.81 MiB   Shape   (2000, 2000)   (1000, 1000)   Dask graph   4 chunks in 75 graph layers   Data type   float32 numpy.ndarray  2000 2000 </li></ul></li><li>Data variables: (3)<ul><li>complex(azimuth, range, time)complex64dask.array&lt;chunksize=(1000, 1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   305.18 MiB   76.29 MiB   Shape   (2000, 2000, 10)   (1000, 1000, 10)   Dask graph   4 chunks in 713 graph layers   Data type   complex64 numpy.ndarray  10 2000 2000 </li><li>amplitude(azimuth, range, time)float32dask.array&lt;chunksize=(1000, 1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   152.59 MiB   38.15 MiB   Shape   (2000, 2000, 10)   (1000, 1000, 10)   Dask graph   4 chunks in 716 graph layers   Data type   float32 numpy.ndarray  10 2000 2000 </li><li>phase(azimuth, range, time)float32dask.array&lt;chunksize=(1000, 1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   152.59 MiB   38.15 MiB   Shape   (2000, 2000, 10)   (1000, 1000, 10)   Dask graph   4 chunks in 716 graph layers   Data type   float32 numpy.ndarray  10 2000 2000 </li></ul></li><li>Indexes: (3)<ul><li>azimuthPandasIndex<pre>PandasIndex(Index([   0.0,    1.0,    2.0,    3.0,    4.0,    5.0,    6.0,    7.0,    8.0,\n          9.0,\n       ...\n       1990.0, 1991.0, 1992.0, 1993.0, 1994.0, 1995.0, 1996.0, 1997.0, 1998.0,\n       1999.0],\n      dtype='float64', name='azimuth', length=2000))</pre></li><li>rangePandasIndex<pre>PandasIndex(Index([   0.5,    2.5,    4.5,    6.5,    8.5,   10.5,   12.5,   14.5,   16.5,\n         18.5,\n       ...\n       3980.5, 3982.5, 3984.5, 3986.5, 3988.5, 3990.5, 3992.5, 3994.5, 3996.5,\n       3998.5],\n      dtype='float64', name='range', length=2000))</pre></li><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (1)multi-look :coarsen-mean</li></ul> In\u00a0[8]: Copied! <pre>mrm = stack_multilook.slcstack.mrm()\nmrm\n</pre> mrm = stack_multilook.slcstack.mrm() mrm Out[8]: <pre>&lt;xarray.DataArray 'amplitude' (azimuth: 2000, range: 2000)&gt;\ndask.array&lt;mean_agg-aggregate, shape=(2000, 2000), dtype=float32, chunksize=(1000, 1000), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth  (azimuth) float64 0.0 1.0 2.0 3.0 ... 1.997e+03 1.998e+03 1.999e+03\n  * range    (range) float64 0.5 2.5 4.5 6.5 ... 3.994e+03 3.996e+03 3.998e+03\n    lat      (azimuth, range) float32 dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;\n    lon      (azimuth, range) float32 dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;</pre>xarray.DataArray'amplitude'<ul><li>azimuth: 2000</li><li>range: 2000</li></ul><ul><li>dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;  Array   Chunk   Bytes   15.26 MiB   3.81 MiB   Shape   (2000, 2000)   (1000, 1000)   Dask graph   4 chunks in 718 graph layers   Data type   float32 numpy.ndarray  2000 2000 </li><li>Coordinates: (4)<ul><li>azimuth(azimuth)float640.0 1.0 2.0 ... 1.998e+03 1.999e+03<pre>array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.997e+03, 1.998e+03, 1.999e+03])</pre></li><li>range(range)float640.5 2.5 4.5 ... 3.996e+03 3.998e+03<pre>array([5.0000e-01, 2.5000e+00, 4.5000e+00, ..., 3.9945e+03, 3.9965e+03,\n       3.9985e+03])</pre></li><li>lat(azimuth, range)float32dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;  Array   Chunk   Bytes   15.26 MiB   3.81 MiB   Shape   (2000, 2000)   (1000, 1000)   Dask graph   4 chunks in 75 graph layers   Data type   float32 numpy.ndarray  2000 2000 </li><li>lon(azimuth, range)float32dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;  Array   Chunk   Bytes   15.26 MiB   3.81 MiB   Shape   (2000, 2000)   (1000, 1000)   Dask graph   4 chunks in 75 graph layers   Data type   float32 numpy.ndarray  2000 2000 </li></ul></li><li>Indexes: (2)<ul><li>azimuthPandasIndex<pre>PandasIndex(Index([   0.0,    1.0,    2.0,    3.0,    4.0,    5.0,    6.0,    7.0,    8.0,\n          9.0,\n       ...\n       1990.0, 1991.0, 1992.0, 1993.0, 1994.0, 1995.0, 1996.0, 1997.0, 1998.0,\n       1999.0],\n      dtype='float64', name='azimuth', length=2000))</pre></li><li>rangePandasIndex<pre>PandasIndex(Index([   0.5,    2.5,    4.5,    6.5,    8.5,   10.5,   12.5,   14.5,   16.5,\n         18.5,\n       ...\n       3980.5, 3982.5, 3984.5, 3986.5, 3988.5, 3990.5, 3992.5, 3994.5, 3996.5,\n       3998.5],\n      dtype='float64', name='range', length=2000))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[9]: Copied! <pre># Compute mrm\nmrm = mrm.compute()\n</pre> # Compute mrm mrm = mrm.compute() In\u00a0[10]: Copied! <pre># Visualize\nfrom matplotlib import pyplot as plt\nfig, ax = plt.subplots()\nax.imshow(mrm)\nim = mrm.plot(ax=ax, robust=True, cmap='gray')\nim.set_clim([0, 50000])\n</pre> # Visualize from matplotlib import pyplot as plt fig, ax = plt.subplots() ax.imshow(mrm) im = mrm.plot(ax=ax, robust=True, cmap='gray') im.set_clim([0, 50000]) In\u00a0[11]: Copied! <pre># Select a subset\nstack_subset = stack.sel(azimuth=range(100,1800), range=range(1000,3000))\n\n# Perform point selection\nstm = stack_subset.slcstack.point_selection(threshold=0.20, method=\"amplitude_dispersion\")\nstm\n</pre> # Select a subset stack_subset = stack.sel(azimuth=range(100,1800), range=range(1000,3000))  # Perform point selection stm = stack_subset.slcstack.point_selection(threshold=0.20, method=\"amplitude_dispersion\") stm Out[11]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (time: 10, points: 78582)\nCoordinates:\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\n    lat        (points) float32 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\n    lon        (points) float32 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\n    azimuth    (points) int64 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\n    range      (points) int64 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\nDimensions without coordinates: points\nData variables:\n    complex    (points, time) complex64 dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;\n    amplitude  (points, time) float32 dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;\n    phase      (points, time) float32 dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 10</li><li>points: 78582</li></ul></li><li>Coordinates: (5)<ul><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li><li>lat(points)float32dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   3.91 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 77 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>lon(points)float32dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   3.91 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 77 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>azimuth(points)int64dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   7.81 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 1 graph layer   Data type   int64 numpy.ndarray  78582 1 </li><li>range(points)int64dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   7.81 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 1 graph layer   Data type   int64 numpy.ndarray  78582 1 </li></ul></li><li>Data variables: (3)<ul><li>complex(points, time)complex64dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   6.00 MiB   78.12 kiB   Shape   (78582, 10)   (1000, 10)   Dask graph   79 chunks in 717 graph layers   Data type   complex64 numpy.ndarray  10 78582 </li><li>amplitude(points, time)float32dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   39.06 kiB   Shape   (78582, 10)   (1000, 10)   Dask graph   79 chunks in 720 graph layers   Data type   float32 numpy.ndarray  10 78582 </li><li>phase(points, time)float32dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   39.06 kiB   Shape   (78582, 10)   (1000, 10)   Dask graph   79 chunks in 720 graph layers   Data type   float32 numpy.ndarray  10 78582 </li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (1)multi-look :coarsen-mean</li></ul> In\u00a0[12]: Copied! <pre>from matplotlib import pyplot as plt\nfig, ax = plt.subplots()\nplt.scatter(stm.lon.data, stm.lat.data, s=0.1)\n</pre> from matplotlib import pyplot as plt fig, ax = plt.subplots() plt.scatter(stm.lon.data, stm.lat.data, s=0.1) Out[12]: <pre>&lt;matplotlib.collections.PathCollection at 0x7f3ce9598c10&gt;</pre> <p>The selected points can be saved to a <code>Zarr</code> storage</p> In\u00a0[13]: Copied! <pre># Export to Zarr\nstm.to_zarr(\"stm.zarr\", mode=\"w\")\n</pre> # Export to Zarr stm.to_zarr(\"stm.zarr\", mode=\"w\") Out[13]: <pre>&lt;xarray.backends.zarr.ZarrStore at 0x7f3ce9135cb0&gt;</pre> <p>And can be read by <code>xr.open_zarr</code></p> In\u00a0[14]: Copied! <pre># Load exported STM in Zarr\nimport xarray as xr\nstm_read = xr.open_zarr(\"stm.zarr\")\nstm_read\n</pre> # Load exported STM in Zarr import xarray as xr stm_read = xr.open_zarr(\"stm.zarr\") stm_read Out[14]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (points: 78582, time: 10)\nCoordinates:\n    azimuth    (points) int64 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\n    lat        (points) float32 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\n    lon        (points) float32 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\n    range      (points) int64 dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\nDimensions without coordinates: points\nData variables:\n    amplitude  (points, time) float32 dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;\n    complex    (points, time) complex64 dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;\n    phase      (points, time) float32 dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>points: 78582</li><li>time: 10</li></ul></li><li>Coordinates: (5)<ul><li>azimuth(points)int64dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   7.81 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 2 graph layers   Data type   int64 numpy.ndarray  78582 1 </li><li>lat(points)float32dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   3.91 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 2 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>lon(points)float32dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   306.96 kiB   3.91 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 2 graph layers   Data type   float32 numpy.ndarray  78582 1 </li><li>range(points)int64dask.array&lt;chunksize=(1000,), meta=np.ndarray&gt;  Array   Chunk   Bytes   613.92 kiB   7.81 kiB   Shape   (78582,)   (1000,)   Dask graph   79 chunks in 2 graph layers   Data type   int64 numpy.ndarray  78582 1 </li><li>time(time)int640 1 2 3 4 5 6 7 8 9<pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></li></ul></li><li>Data variables: (3)<ul><li>amplitude(points, time)float32dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   39.06 kiB   Shape   (78582, 10)   (1000, 10)   Dask graph   79 chunks in 2 graph layers   Data type   float32 numpy.ndarray  10 78582 </li><li>complex(points, time)complex64dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   6.00 MiB   78.12 kiB   Shape   (78582, 10)   (1000, 10)   Dask graph   79 chunks in 2 graph layers   Data type   complex64 numpy.ndarray  10 78582 </li><li>phase(points, time)float32dask.array&lt;chunksize=(1000, 10), meta=np.ndarray&gt;  Array   Chunk   Bytes   3.00 MiB   39.06 kiB   Shape   (78582, 10)   (1000, 10)   Dask graph   79 chunks in 2 graph layers   Data type   float32 numpy.ndarray  10 78582 </li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64', name='time'))</pre></li></ul></li><li>Attributes: (1)multi-look :coarsen-mean</li></ul>"},{"location":"notebooks/demo_sarxarray/#example-jupyter-notebook","title":"Example Jupyter Notebook\u00b6","text":""},{"location":"notebooks/demo_sarxarray/#data-used-for-this-notebook","title":"Data used for this Notebook\u00b6","text":"<ul> <li>Sentinel-1 interferogram stack over Amsterdam</li> </ul>"},{"location":"notebooks/demo_sarxarray/#setup-environment","title":"Setup environment\u00b6","text":"<p>For the python environment setup, we assume you already installed SARXarray following the installation guide.</p> <p>Some extra python dependencies are required to execute this notebook. You can install the extra python dependencies by:</p> <pre>pip install sarxarray[demo]\n</pre> <p>After installation, execute the notebook in a JupyterLab session, which can be started by running <code>jupyterlab</code> command in your command line:</p> <pre>jupyter-lab\n</pre> <p>A new tab will be opened in your default browser to execute this notebook.</p>"},{"location":"notebooks/demo_sarxarray/#load-a-interferogram-stack","title":"Load a interferogram stack\u00b6","text":""},{"location":"notebooks/demo_sarxarray/#append-georeferenced-coordinates-as-new-data-fields","title":"Append georeferenced coordinates as new data fields\u00b6","text":"<p>The <code>sarxarray</code> is implemented as an extension of <code>Xarray.Dataset</code>, which means we can modify the <code>stack</code> variable as a normal <code>Dataset</code> objet. For example, we can load in the georeference coordinates (lattitude and longitude) also with <code>from_binary</code>, and attach them to <code>stack</code>.</p>"},{"location":"notebooks/demo_sarxarray/#multi-looking","title":"Multi-Looking\u00b6","text":""},{"location":"notebooks/demo_sarxarray/#create-mrm-of-a-subset","title":"Create MRM of a subset\u00b6","text":"<p>We will compute a Mean Reflection Map (MRM) using a subset of the stack.</p>"},{"location":"notebooks/demo_sarxarray/#export-to-a-space-time-matrix","title":"Export to a Space Time Matrix\u00b6","text":"<p>To prepare the data for PSI processing, we can select temporal consistant pixels, and transform them into a Space-Time Matrix. This can be done using the <code>point_selection</code> function</p>"},{"location":"notebooks/demo_sarxarray_spider/","title":"Spider Example","text":"<p>In this Jupyter Notebook, we demonstrate the following operations using <code>sarxarray</code>:</p> <ul> <li>Load an SLC stack in binary format into a <code>xarray.Dataset</code> object;</li> <li>Append variable data fields;</li> <li>Create an MRM of a subset of the SLC stack;</li> <li>Apply point selection to a subset of the SLC stack;</li> <li>Export the selection results in Zarr format</li> </ul> In\u00a0[3]: Copied! <pre>import numpy as np\nfrom pathlib import Path\nimport sarxarray\n</pre> import numpy as np from pathlib import Path import sarxarray In\u00a0[4]: Copied! <pre># You many need to change this cell to your local data directory\npath = Path('/project/caroline/Share/stacks/nl_veenweiden_s1_asc_t088/stack')\n</pre> # You many need to change this cell to your local data directory path = Path('/project/caroline/Share/stacks/nl_veenweiden_s1_asc_t088/stack') In\u00a0[5]: Copied! <pre># Make a list of SLCs to read\nf_slc = 'cint.raw' \nlist_slcs = [p/f_slc for p in path.rglob(('[0-9]' * 8)) if not p.match('20200325')]\n</pre> # Make a list of SLCs to read f_slc = 'cint.raw'  list_slcs = [p/f_slc for p in path.rglob(('[0-9]' * 8)) if not p.match('20200325')] In\u00a0[6]: Copied! <pre>len(list_slcs)\n</pre> len(list_slcs) Out[6]: <pre>374</pre> In\u00a0[9]: Copied! <pre># Read metadata\nshape=(10018, 68656)\ndtype = np.dtype([('re', np.float32), ('im', np.float32)])\n</pre> # Read metadata shape=(10018, 68656) dtype = np.dtype([('re', np.float32), ('im', np.float32)]) In\u00a0[10]: Copied! <pre>stack = sarxarray.from_binary(list_slcs, shape, dtype=dtype)\nstack\n</pre> stack = sarxarray.from_binary(list_slcs, shape, dtype=dtype) stack Out[10]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 10018, range: 68656, time: 374)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 ... 10013 10014 10015 10016 10017\n  * range      (range) int64 0 1 2 3 4 5 ... 68650 68651 68652 68653 68654 68655\n  * time       (time) int64 0 1 2 3 4 5 6 7 ... 366 367 368 369 370 371 372 373\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>azimuth: 10018</li><li>range: 68656</li><li>time: 374</li></ul></li><li>Coordinates: (3)<ul><li>azimuth(azimuth)int640 1 2 3 ... 10014 10015 10016 10017<pre>array([    0,     1,     2, ..., 10015, 10016, 10017])</pre></li><li>range(range)int640 1 2 3 ... 68652 68653 68654 68655<pre>array([    0,     1,     2, ..., 68653, 68654, 68655])</pre></li><li>time(time)int640 1 2 3 4 5 ... 369 370 371 372 373<pre>array([  0,   1,   2, ..., 371, 372, 373])</pre></li></ul></li><li>Data variables: (3)<ul><li>complex(azimuth, range, time)complex64dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   1.87 TiB   122.07 MiB   Shape   (10018, 68656, 374)   (4000, 4000, 1)   Dask graph   20196 chunks in 42638 graph layers   Data type   complex64 numpy.ndarray  374 68656 10018 </li><li>amplitude(azimuth, range, time)float32dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   0.94 TiB   61.04 MiB   Shape   (10018, 68656, 374)   (4000, 4000, 1)   Dask graph   20196 chunks in 42641 graph layers   Data type   float32 numpy.ndarray  374 68656 10018 </li><li>phase(azimuth, range, time)float32dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   0.94 TiB   61.04 MiB   Shape   (10018, 68656, 374)   (4000, 4000, 1)   Dask graph   20196 chunks in 42641 graph layers   Data type   float32 numpy.ndarray  374 68656 10018 </li></ul></li><li>Indexes: (3)<ul><li>azimuthPandasIndex<pre>PandasIndex(Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n                9,\n            ...\n            10008, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016,\n            10017],\n           dtype='int64', name='azimuth', length=10018))</pre></li><li>rangePandasIndex<pre>PandasIndex(Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n                9,\n            ...\n            68646, 68647, 68648, 68649, 68650, 68651, 68652, 68653, 68654,\n            68655],\n           dtype='int64', name='range', length=68656))</pre></li><li>timePandasIndex<pre>PandasIndex(Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n            ...\n            364, 365, 366, 367, 368, 369, 370, 371, 372, 373],\n           dtype='int64', name='time', length=374))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[11]: Copied! <pre>stack.complex\n</pre> stack.complex Out[11]: <pre>&lt;xarray.DataArray 'complex' (azimuth: 10018, range: 68656, time: 374)&gt;\ndask.array&lt;transpose, shape=(10018, 68656, 374), dtype=complex64, chunksize=(4000, 4000, 1), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth  (azimuth) int64 0 1 2 3 4 5 ... 10012 10013 10014 10015 10016 10017\n  * range    (range) int64 0 1 2 3 4 5 6 ... 68650 68651 68652 68653 68654 68655\n  * time     (time) int64 0 1 2 3 4 5 6 7 8 ... 366 367 368 369 370 371 372 373</pre>xarray.DataArray'complex'<ul><li>azimuth: 10018</li><li>range: 68656</li><li>time: 374</li></ul><ul><li>dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;  Array   Chunk   Bytes   1.87 TiB   122.07 MiB   Shape   (10018, 68656, 374)   (4000, 4000, 1)   Dask graph   20196 chunks in 42638 graph layers   Data type   complex64 numpy.ndarray  374 68656 10018 </li><li>Coordinates: (3)<ul><li>azimuth(azimuth)int640 1 2 3 ... 10014 10015 10016 10017<pre>array([    0,     1,     2, ..., 10015, 10016, 10017])</pre></li><li>range(range)int640 1 2 3 ... 68652 68653 68654 68655<pre>array([    0,     1,     2, ..., 68653, 68654, 68655])</pre></li><li>time(time)int640 1 2 3 4 5 ... 369 370 371 372 373<pre>array([  0,   1,   2, ..., 371, 372, 373])</pre></li></ul></li><li>Indexes: (3)<ul><li>azimuthPandasIndex<pre>PandasIndex(Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n                9,\n            ...\n            10008, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016,\n            10017],\n           dtype='int64', name='azimuth', length=10018))</pre></li><li>rangePandasIndex<pre>PandasIndex(Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n                9,\n            ...\n            68646, 68647, 68648, 68649, 68650, 68651, 68652, 68653, 68654,\n            68655],\n           dtype='int64', name='range', length=68656))</pre></li><li>timePandasIndex<pre>PandasIndex(Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n            ...\n            364, 365, 366, 367, 368, 369, 370, 371, 372, 373],\n           dtype='int64', name='time', length=374))</pre></li></ul></li><li>Attributes: (0)</li></ul> <p>Here you can use the dask plugin on the left side of your Jupyter panel, and spin up workers</p> In\u00a0[12]: Copied! <pre>from dask.distributed import Client\n\nclient = Client(\"tcp://10.0.4.11:37383\")\nclient\n</pre> from dask.distributed import Client  client = Client(\"tcp://10.0.4.11:37383\") client Out[12]: Client <p>Client-479c0fe4-a604-11ed-a629-fa163e6bae42</p> Connection method: Direct Dashboard:  /proxy/8787/status                  Launch dashboard in JupyterLab              Scheduler Info Scheduler <p>Scheduler-5402bc8c-f88f-4a67-ad49-4a227fc9b2c6</p> Comm: tcp://10.0.4.11:37383                      Workers: 4                      Dashboard: /proxy/8787/status Total threads: 16                      Started: 4 minutes ago                      Total memory: 120.00 GiB                      Workers Worker: SLURMCluster-0 Comm:  tcp://10.0.2.120:33813                          Total threads:  4                          Dashboard:  /proxy/8787/status Memory:  30.00 GiB                          Nanny:  tcp://10.0.2.120:33505                          Local directory:  /tmp/dask-worker-space/worker-9b_frli1                          Tasks executing:  Tasks in memory:  Tasks ready:  Tasks in flight:  CPU usage: 2.0%                          Last seen:  Just now                          Memory usage:  98.94 MiB                          Spilled bytes:  0 B                          Read bytes:  1.52 kiB                          Write bytes:  3.00 kiB                          Worker: SLURMCluster-1 Comm:  tcp://10.0.1.29:39357                          Total threads:  4                          Dashboard:  /proxy/8787/status Memory:  30.00 GiB                          Nanny:  tcp://10.0.1.29:45985                          Local directory:  /tmp/dask-worker-space/worker-2rdobvm1                          Tasks executing:  Tasks in memory:  Tasks ready:  Tasks in flight:  CPU usage: 2.0%                          Last seen:  Just now                          Memory usage:  102.85 MiB                          Spilled bytes:  0 B                          Read bytes:  1.11 kiB                          Write bytes:  2.17 kiB                          Worker: SLURMCluster-2 Comm:  tcp://10.0.2.38:45309                          Total threads:  4                          Dashboard:  /proxy/8787/status Memory:  30.00 GiB                          Nanny:  tcp://10.0.2.38:39251                          Local directory:  /tmp/dask-worker-space/worker-lkpobizc                          Tasks executing:  Tasks in memory:  Tasks ready:  Tasks in flight:  CPU usage: 2.0%                          Last seen:  Just now                          Memory usage:  97.44 MiB                          Spilled bytes:  0 B                          Read bytes:  285.44855889787453 B                          Write bytes:  1.47 kiB                          Worker: SLURMCluster-3 Comm:  tcp://10.0.1.207:35015                          Total threads:  4                          Dashboard:  /proxy/8787/status Memory:  30.00 GiB                          Nanny:  tcp://10.0.1.207:39823                          Local directory:  /tmp/dask-worker-space/worker-msu2cfmu                          Tasks executing:  Tasks in memory:  Tasks ready:  Tasks in flight:  CPU usage: 2.0%                          Last seen:  Just now                          Memory usage:  98.96 MiB                          Spilled bytes:  0 B                          Read bytes:  286.1167082603562 B                          Write bytes:  1.47 kiB                          In\u00a0[13]: Copied! <pre>mrm = stack.slcstack.mrm()\nmrm\n</pre> mrm = stack.slcstack.mrm() mrm Out[13]: <pre>&lt;xarray.DataArray 'amplitude' (azimuth: 10018, range: 68656)&gt;\ndask.array&lt;mean_agg-aggregate, shape=(10018, 68656), dtype=float32, chunksize=(4000, 4000), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth  (azimuth) int64 0 1 2 3 4 5 ... 10012 10013 10014 10015 10016 10017\n  * range    (range) int64 0 1 2 3 4 5 6 ... 68650 68651 68652 68653 68654 68655</pre>xarray.DataArray'amplitude'<ul><li>azimuth: 10018</li><li>range: 68656</li></ul><ul><li>dask.array&lt;chunksize=(4000, 4000), meta=np.ndarray&gt;  Array   Chunk   Bytes   2.56 GiB   61.04 MiB   Shape   (10018, 68656)   (4000, 4000)   Dask graph   54 chunks in 42647 graph layers   Data type   float32 numpy.ndarray  68656 10018 </li><li>Coordinates: (2)<ul><li>azimuth(azimuth)int640 1 2 3 ... 10014 10015 10016 10017<pre>array([    0,     1,     2, ..., 10015, 10016, 10017])</pre></li><li>range(range)int640 1 2 3 ... 68652 68653 68654 68655<pre>array([    0,     1,     2, ..., 68653, 68654, 68655])</pre></li></ul></li><li>Indexes: (2)<ul><li>azimuthPandasIndex<pre>PandasIndex(Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n                9,\n            ...\n            10008, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016,\n            10017],\n           dtype='int64', name='azimuth', length=10018))</pre></li><li>rangePandasIndex<pre>PandasIndex(Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n                9,\n            ...\n            68646, 68647, 68648, 68649, 68650, 68651, 68652, 68653, 68654,\n            68655],\n           dtype='int64', name='range', length=68656))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[14]: Copied! <pre># Compute a subset of the mrm\nmrm_subset = mrm[5000:5100, 10000:10100]\nmrm_subset = mrm_subset.compute()\n</pre> # Compute a subset of the mrm mrm_subset = mrm[5000:5100, 10000:10100] mrm_subset = mrm_subset.compute() In\u00a0[17]: Copied! <pre># Visualize\nfrom matplotlib import pyplot as plt\nfig, ax = plt.subplots()\nax.imshow(mrm_subset)\nmrm_subset.plot(robust=True, ax=ax)\n</pre> # Visualize from matplotlib import pyplot as plt fig, ax = plt.subplots() ax.imshow(mrm_subset) mrm_subset.plot(robust=True, ax=ax) Out[17]: <pre>&lt;matplotlib.collections.QuadMesh at 0x7f72dd4565d0&gt;</pre>"},{"location":"notebooks/demo_sarxarray_spider/#spider-example","title":"Spider Example\u00b6","text":""},{"location":"notebooks/demo_sarxarray_spider/#load-a-slc-stack","title":"Load a SLC stack\u00b6","text":""},{"location":"notebooks/demo_sarxarray_spider/#create-mrm-of-a-subset","title":"Create MRM of a subset\u00b6","text":""}]}