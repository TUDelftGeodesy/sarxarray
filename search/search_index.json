{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SARXarray","text":"<p>SARXarray is an open-source Xarray extension for Synthetic Aperture Radar (SAR) data.</p> <p>SARXarray is especially designed to work with complex data, that is, containing both the phase and amplitude of the data. The extension can handle coregistered stacks of Single Look Complex (SLC) data, as well as derived products such as interferogram stacks. It utilizes Xarray\u2019s support on labeled multi-dimensional datasets to stress the space-time character of the image stacks. Dask Array is implemented to support parallel computation.</p> <p>SARXarry supports the following functionalities:</p> <ol> <li> <p>Chunk-wise reading/writing of coregistered SLC or interferogram stacks;</p> </li> <li> <p>Basic operations on complex data, e.g., averaging along axis and complex conjugate multiplication;</p> </li> <li> <p>Specific SAR data operations, e.g., multi-looking and coherence estimation.</p> </li> </ol> <p>All the above functionalities can be scaled up to a Hyper-Performance Computation (HPC) system.</p>"},{"location":"CHANGELOG/","title":"Change Log","text":"<p>All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning.</p> <p>[0.1.0] - 2023-11-06</p>"},{"location":"CHANGELOG/#added","title":"Added","text":"<p>The first version of the SARXarray package. The following functionalities are implemented: - Data loading function for large SAR/interferogram stack; - Basic SAR raster operations: multi-look, coherence, and MRM; - Scatterer selection based on amplitude dispersion; - Relevant docs and tests.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":"<p>This code of conduct is adapted from the  Git Code of Conduct.</p>"},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Project maintainers are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at team-atlas@esciencecenter.nl.</p> <p>All complaints will be reviewed and investigated promptly and fairly.</p> <p>All Project maintainers are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4,  available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p>"},{"location":"CONTRIBUTING/","title":"SARXarray Contributing Guidelines","text":"<p>We welcome any kind of contribution to our software, from a simple comment  or question to a full fledged pull request.  Please read and follow our Code of Conduct.</p> <p>A contribution can be one of the following cases:</p> <ul> <li>you have a question;</li> <li>you think you may have found a bug (including unexpected behavior);</li> <li>you want to make some kind of change to the code base (e.g. to fix a bug, to add a new feature, to update documentation).</li> </ul> <p>The sections below outline the steps in each case.</p>"},{"location":"CONTRIBUTING/#you-have-a-question","title":"You have a question","text":"<ul> <li>use the search functionality in GitHub issue to see if someone already filed the same issue;</li> <li>if your issue search did not yield any relevant results, create a new issue;</li> <li>add the \"question\" label; include other labels when relevant.</li> </ul>"},{"location":"CONTRIBUTING/#you-think-you-may-have-found-a-bug","title":"You think you may have found a bug","text":"<ul> <li>use the search functionality in GitHub issue to see if someone already filed the same issue;</li> <li>if your issue search did not yield any relevant results, create a new issue, making sure to provide enough information to the rest of the community to understand the cause and context of the problem. Depending on the issue, you may want to include:<ul> <li>the SHA hashcode of the commit that is causing your problem;</li> <li>some identifying information (name and version number) for dependencies you're using;</li> <li>information about the operating system;</li> </ul> </li> <li>add relevant labels to the newly created issue.</li> </ul>"},{"location":"CONTRIBUTING/#you-want-to-make-some-kind-of-change-to-the-code-base","title":"You want to make some kind of change to the code base","text":"<ul> <li>(important) announce your plan to the rest of the community before you start working. This announcement should be in the form of a (new) issue;</li> <li>(important) wait until some kind of consensus is reached about your idea being a good idea;</li> <li>if needed, fork the repository to your own Github profile and create your own feature branch off of the latest master commit. While working on your feature branch, make sure to stay up to date with the master branch by pulling in changes, possibly from the 'upstream' repository (follow the instructions from GitHub: instruction 1: configuring a remote for a fork and instruction 2: syncing a fork);</li> <li>install the pre-commit hooks by running <code>pre-commit install</code> in the project root directory;</li> <li>make sure the existing tests still work by running, e.g. <code>pytest tests</code>;</li> <li>add your own tests (if necessary);</li> <li>update or expand the documentation;</li> <li>make sure the linting tests pass by running <code>ruff</code> in the project root directory: <code>ruff check .</code>;</li> <li>push your feature branch to (your fork of) the sarxarray repository on GitHub;</li> <li>create the pull request, e.g. following the instructions: creating a pull request.</li> </ul> <p>In case you feel like you've made a valuable contribution, but you don't know how to write or run tests for it, or how to generate the documentation: don't let this discourage you from making the pull request; we can help you! Just go ahead and submit the pull request, but keep in mind that you might be asked to append additional commits to your pull request.</p>"},{"location":"common_ops/","title":"Common SLC operations","text":"<p>Details about the common operations in this page are coming soon...</p> <p>Common SAR processings can be performed by SARXarray. Below are some examples:</p>"},{"location":"common_ops/#multi-look","title":"Multi-look","text":"<p>Multi-look by a windowsize of e.g. 2 in azimuth dimension and 4 in range dimension:</p> <pre><code>stack_multilook = stack.slcstack.multi_look((2,4))\n</code></pre>"},{"location":"common_ops/#coherence","title":"Coherence","text":"<p>Compute coherence between two SLCs:</p> <pre><code>from sarxarray import complex_coherence\nslc1 = stack.complex.isel(time=0) # first image\nslc2 = stack.complex.isel(time=2) # third image\nwindow = (4,4)\n\ncoherence = complex_coherence(slc1, slc2, window)\n</code></pre>"},{"location":"common_ops/#mean-reflection-map-mrm","title":"Mean-Reflection-Map (MRM)","text":"<pre><code>mrm = stack_multilook.slcstack.mrm()\n</code></pre> <pre><code>from matplotlib import pyplot as plt\nfig, ax = plt.subplots()\nax.imshow(mrm)\nmrm.plot(ax=ax, robust=True, cmap='gray')\n</code></pre>"},{"location":"common_ops/#point-selection","title":"Point selection","text":"<p>A selection based on temporal properties per pixel can be performed. For example, we can select the Point Scatterers (PS) by normalized temporal dispersion of <code>amplitude</code>:</p> <pre><code>ps = stack.slcstack.point_selection(threshold=0.25, method=\"amplitude_dispersion\")\n</code></pre>"},{"location":"data_loading/","title":"Usage","text":""},{"location":"data_loading/#input-data-format","title":"Input data format","text":"<p>SARXarray works with coregistered SLC/interferogram stack. SARXarray provides a reader to perform lazy loading on data stacks in different file formats, including binary format. However, we recommend to store the coregistered stack in <code>zarr</code> format, and directly load them as an Xarray object by <code>xarray.open_zarr</code>. </p>"},{"location":"data_loading/#loading-coregistered-slc-stack-in-binary-format","title":"Loading coregistered SLC stack in binary format","text":"<p>If the stack is saved in binary format, it can be read by <code>SARXarray</code> under two pre-requisites:</p> <ol> <li>All SLCs/interferograms have the same known raster size and data type;</li> <li>All SLCs/interferograms have been resampled to the same raster grid.</li> </ol> <p>For example, let's consider a case of a stack with three SLCs:</p> <pre><code>import numpy as np\nlist_slcs = ['data/slc_1.raw', 'data/slc_2.raw', 'data/slc_3.raw']\nshape = (10018, 68656) # (azimuth, range)\ndtype = np.complex64\n</code></pre> <p>We built a list <code>list_slcs</code> with the paths to the SLCs. In this case they are stored in the same directory called <code>data</code>. The shape of each SLC should be provided, i.e.: <code>10018</code> pixels in <code>azimuth</code> direction, and <code>68656</code> in range direction. The data type is <code>numpy.complex64</code>.</p> <p>The coregistered SLC stack can be read using the <code>from_binary</code> function:</p> <p><pre><code>import sarxarray\n\nstack = sarxarray.from_binary(list_slcs, shape, dtype=dtype)\n</code></pre> You can also skip the <code>dtype</code> argument since it's defaulted to <code>numpy.complex64</code>. The stack will be read as an <code>xarray.Dataset</code> object, with data variables lazily loaded as <code>Dask Array</code>:</p> <pre><code>print(stack)\n</code></pre> <pre><code>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 10018, range: 68656, time: 3)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 ... 10013 10014 10015 10016 10017\n  * range      (range) int64 0 1 2 3 4 5 ... 68650 68651 68652 68653 68654 68655\n  * time       (time) int64 0 1 2\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(4000, 4000, 1), meta=np.ndarray&gt;\n</code></pre> <p>The loading chunk size can also be specified manually:</p> <pre><code>stack_smallchunk = sarxarray.from_binary(list_slcs, shape, chunks=(2000, 2000))\n</code></pre>"},{"location":"manipulations/","title":"Manipulate an SLC stack as an Xarray","text":"<p>The loaded stack can be manipulated as an <code>Xarray.Dataset</code> instance.</p> <p>Slice the SLC stack in 3D:</p> <pre><code>stack.isel(azimuth=range(1000,2000), range=range(1500,2500), time=range(2,5))\n</code></pre> <p>Select the <code>amplitude</code> attribute <pre><code>amp = stack['amplitude']\n</code></pre></p> <p>Compute stack and persist in memory: <pre><code>stack = stack.compute()\n</code></pre></p>"},{"location":"setup/","title":"Installation","text":"<p>SARXarray can be installed from PyPI:</p> <pre><code>pip install sarxarray\n</code></pre> <p>or from the source:</p> <pre><code>git clone git@github.com:TUDelftGeodesy/sarxarray.git\ncd sarxarray\npip install .\n</code></pre> <p>Note that Python version <code>&gt;=3.10</code> is required for SARXarray.</p>"},{"location":"setup/#tips","title":"Tips","text":"<p>We strongly recommend installing separately from your default Python environment. E.g. you can use environment manager (e.g. mamba) to create a separate environment.</p>"},{"location":"notebooks/demo_sarxarray/","title":"Example Notebook","text":"<p>You can download this Jupyter Notebook via the download button at the top of this page.</p> <p>In this Jupyter Notebook, we demonstrate the following operations using <code>sarxarray</code>:</p> <ul> <li>Load an interferogram stack in binary format into a <code>xarray.Dataset</code> object;</li> <li>Append latitude and longitude coordinates to the loaded stack;</li> <li>Create an Mean-Reflection-Map (MRM) of a subset of the interferogram stack;</li> <li>Apply common SAR processing steps to the interferogram stack;</li> </ul> In\u00a0[1]: Copied! <pre>import numpy as np\nfrom pathlib import Path\nimport sarxarray\n</pre> import numpy as np from pathlib import Path import sarxarray <p>We will load the interferogram stack, which has been coregistered and saved as binary files. We assume the shape and data type is known.</p> In\u00a0[2]: Copied! <pre># Path to the interferogram dataset\npath = Path('nl_amsterdam_s1_asc_t088')\n\n# Make a list of interferograms to read\nlist_ifgs = [p for p in path.rglob('*_cint_srd.raw')]\nlist_ifgs.sort()\n\n# Metadata of the stack, assume known.\nshape=(2000, 4000)\n\n# Define reading chunks\nreading_chunks = (500,500)\n</pre> # Path to the interferogram dataset path = Path('nl_amsterdam_s1_asc_t088')  # Make a list of interferograms to read list_ifgs = [p for p in path.rglob('*_cint_srd.raw')] list_ifgs.sort()  # Metadata of the stack, assume known. shape=(2000, 4000)  # Define reading chunks reading_chunks = (500,500) In\u00a0[3]: Copied! <pre># Check the list of interferograms\nprint(list_ifgs)\n</pre> # Check the list of interferograms print(list_ifgs) <pre>[PosixPath('nl_amsterdam_s1_asc_t088/20180920_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20180926_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181002_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181008_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181014_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181020_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181026_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181101_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181107_cint_srd.raw'), PosixPath('nl_amsterdam_s1_asc_t088/20181113_cint_srd.raw')]\n</pre> <p>Use <code>from_binary</code> to load the stack:</p> In\u00a0[4]: Copied! <pre># Load complex data\nstack = sarxarray.from_binary(list_ifgs, shape, dtype=np.complex64, chunks=reading_chunks)\n\nprint(stack)\n</pre> # Load complex data stack = sarxarray.from_binary(list_ifgs, shape, dtype=np.complex64, chunks=reading_chunks)  print(stack) <pre>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 2000, range: 4000, time: 10)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * range      (range) int64 0 1 2 3 4 5 6 ... 3994 3995 3996 3997 3998 3999\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n</pre> In\u00a0[\u00a0]: Copied! <pre># Geo-coordinates\nf_lat = [path / 'lat.raw']\nf_lon = [path / 'lon.raw']\n</pre> # Geo-coordinates f_lat = [path / 'lat.raw'] f_lon = [path / 'lon.raw'] In\u00a0[6]: Copied! <pre># Load coordinates\nlat = sarxarray.from_binary(\n    f_lat, shape, vlabel=\"lat\", dtype=np.float32, chunks=reading_chunks\n)\nlon = sarxarray.from_binary(\n    f_lon, shape, vlabel=\"lon\", dtype=np.float32, chunks=reading_chunks\n)\nstack = stack.assign_coords(\n    lat=((\"azimuth\", \"range\"), lat.squeeze().lat.data),\n    lon=((\"azimuth\", \"range\"), lon.squeeze().lon.data),\n)\n</pre> # Load coordinates lat = sarxarray.from_binary(     f_lat, shape, vlabel=\"lat\", dtype=np.float32, chunks=reading_chunks ) lon = sarxarray.from_binary(     f_lon, shape, vlabel=\"lon\", dtype=np.float32, chunks=reading_chunks ) stack = stack.assign_coords(     lat=((\"azimuth\", \"range\"), lat.squeeze().lat.data),     lon=((\"azimuth\", \"range\"), lon.squeeze().lon.data), ) In\u00a0[7]: Copied! <pre>print(stack)\n</pre> print(stack) <pre>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 2000, range: 4000, time: 10)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * range      (range) int64 0 1 2 3 4 5 6 ... 3994 3995 3996 3997 3998 3999\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\n    lat        (azimuth, range) float32 dask.array&lt;chunksize=(500, 500), meta=np.ndarray&gt;\n    lon        (azimuth, range) float32 dask.array&lt;chunksize=(500, 500), meta=np.ndarray&gt;\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 500, 1), meta=np.ndarray&gt;\n</pre> <p>Some common SAR operations are supported by SARXarray.</p> In\u00a0[8]: Copied! <pre>stack_multilook = stack.slcstack.multi_look((1,2))\nprint(stack_multilook)\n</pre> stack_multilook = stack.slcstack.multi_look((1,2)) print(stack_multilook) <pre>&lt;xarray.Dataset&gt;\nDimensions:    (azimuth: 2000, range: 2000, time: 10)\nCoordinates:\n  * azimuth    (azimuth) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * range      (range) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * time       (time) int64 0 1 2 3 4 5 6 7 8 9\n    lat        (azimuth, range) float32 dask.array&lt;chunksize=(500, 250), meta=np.ndarray&gt;\n    lon        (azimuth, range) float32 dask.array&lt;chunksize=(500, 250), meta=np.ndarray&gt;\nData variables:\n    complex    (azimuth, range, time) complex64 dask.array&lt;chunksize=(500, 250, 1), meta=np.ndarray&gt;\n    amplitude  (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 250, 1), meta=np.ndarray&gt;\n    phase      (azimuth, range, time) float32 dask.array&lt;chunksize=(500, 250, 1), meta=np.ndarray&gt;\nAttributes:\n    multi-look:  coarsen-mean\n</pre> In\u00a0[9]: Copied! <pre>mrm = stack_multilook.slcstack.mrm()\nprint(mrm)\n</pre> mrm = stack_multilook.slcstack.mrm() print(mrm) <pre>&lt;xarray.DataArray 'amplitude' (azimuth: 2000, range: 2000)&gt;\ndask.array&lt;mean_agg-aggregate, shape=(2000, 2000), dtype=float32, chunksize=(500, 250), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * azimuth  (azimuth) int64 0 1 2 3 4 5 6 ... 1994 1995 1996 1997 1998 1999\n  * range    (range) int64 0 1 2 3 4 5 6 ... 1993 1994 1995 1996 1997 1998 1999\n    lat      (azimuth, range) float32 dask.array&lt;chunksize=(500, 250), meta=np.ndarray&gt;\n    lon      (azimuth, range) float32 dask.array&lt;chunksize=(500, 250), meta=np.ndarray&gt;\n</pre> In\u00a0[10]: Copied! <pre># Visualize\nfrom matplotlib import pyplot as plt\nfig, ax = plt.subplots()\nfig.set_size_inches((5,5))\nax.imshow(mrm)\nim = mrm.plot(ax=ax, robust=True, cmap='gray')\nim.set_clim([0, 50000])\n</pre> # Visualize from matplotlib import pyplot as plt fig, ax = plt.subplots() fig.set_size_inches((5,5)) ax.imshow(mrm) im = mrm.plot(ax=ax, robust=True, cmap='gray') im.set_clim([0, 50000])"},{"location":"notebooks/demo_sarxarray/#example-notebook","title":"Example Notebook\u00b6","text":""},{"location":"notebooks/demo_sarxarray/#setup","title":"Setup\u00b6","text":""},{"location":"notebooks/demo_sarxarray/#data-preparation","title":"Data preparation\u00b6","text":"<p>We use a coregistered and georeferenced Sentinel-1 interferogram stack over Amsterdam as an example dataset. Please download the data and unzip it locally.</p>"},{"location":"notebooks/demo_sarxarray/#environment-setup","title":"Environment setup\u00b6","text":"<p>For the python environment setup, we assume you already installed SARXarray following the installation guide.</p> <p>Some extra python dependencies are required to execute this notebook. You can install the extra python dependencies by:</p> <pre>pip install sarxarray[demo]\n</pre> <p>After installation, execute the notebook in a JupyterLab session, which can be started by running the <code>jupyter-lab</code> command in your command line:</p> <pre>jupyter-lab\n</pre> <p>Alternatively, you can also use Jupyter Notebook.</p> <p>A new tab will be opened in your default browser to execute this notebook.</p>"},{"location":"notebooks/demo_sarxarray/#data-loading","title":"Data loading\u00b6","text":""},{"location":"notebooks/demo_sarxarray/#append-georeferenced-coordinates","title":"Append georeferenced coordinates\u00b6","text":"<p>The <code>sarxarray</code> is implemented as an extension of <code>Xarray.Dataset</code>, which means we can modify the <code>stack</code> variable as a normal <code>Dataset</code> object. For example, we can append geo-coordinates to the loaded stack.</p>"},{"location":"notebooks/demo_sarxarray/#common-sar-operations","title":"Common SAR operations\u00b6","text":""},{"location":"notebooks/demo_sarxarray/#multi-looking","title":"Multi-Looking\u00b6","text":"<p>We apply a <code>(1,2)</code> multi-look to the loaded stack. As a result the size of the output will be <code>(2000,2000)</code>.</p>"},{"location":"notebooks/demo_sarxarray/#mean-reflection-map-mrm","title":"Mean-Reflection-Map (MRM)\u00b6","text":""}]}